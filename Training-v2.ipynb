{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "481166ea-6d7a-4035-9108-38d25a239dff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## todo\n",
    "- negatives. : done\n",
    "- logQ correction : divay\n",
    "- postional encoding : arshi\n",
    "- time feature : done\n",
    "- pl model : done\n",
    "- pl dataset : done\n",
    "- trainer : done\n",
    "- make random for only max_positives : divay\n",
    "- encoder to decoder\n",
    "- positive mask loss removal : done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eba2efb3-4408-4408-a5da-9841f950b116",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd9cac7d-b621-4106-9d0d-76f561b42aa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 11:22:20.067590: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2025-02-20 11:22:20.120933: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-02-20 11:22:20.120959: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-02-20 11:22:20.120984: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-02-20 11:22:20.131150: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import gc\n",
    "import pickle \n",
    "from time import time\n",
    "from google.cloud import storage\n",
    "import math\n",
    "import datetime as datetime\n",
    "import sys\n",
    "import psutil\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as pads\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DistributedSampler, DataLoader, Dataset, IterableDataset\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning import Trainer\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "storage_client = storage.Client()\n",
    "\n",
    "\n",
    "bucket = storage_client.get_bucket('gcs-dsci-fryou-fy-dev-prd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd0c9304-545d-49d7-a9ab-bc90e765e247",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11bc4590-a6bc-484d-8bf1-2a7d48306036",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_equally_distributed_files(files, world_size):\n",
    "    total_files = len(files)\n",
    "    print(\"total files inside fn: \", total_files)\n",
    "    end = (total_files // world_size) * world_size\n",
    "    print(\"value of end inside fn: \", end)\n",
    "    files = files[:end]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5a9b1a8-de5d-44bc-a5ef-58f50be29e14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_index(index_path, entity, special_tokens, shift_index=True):\n",
    "    bucket.blob(blob_name=f\"{index_path}{entity}_index.pkl\").download_to_filename(\n",
    "        f\"{entity}_index.pkl\"\n",
    "    )\n",
    "    with open(f\"{entity}_index.pkl\", \"rb\") as file:\n",
    "        entity_index = pickle.load(file)\n",
    "    if shift_index:\n",
    "        special_tokens_len = len(special_tokens)\n",
    "        entity_index = special_tokens | {k:v+special_tokens_len for k,v in entity_index.items()}\n",
    "    return entity_index, len(entity_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cf36d6b-97f0-4a54-b120-af31f6ded2c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6112f00-3226-481d-8199-d81719179602",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class SeqDataSet(IterableDataset):\n",
    "    def __init__(self, files, behaviour_context_length, all_dense_perc, future_window, max_positives, negatives, batch_size):\n",
    "        super().__init__()\n",
    "        self.files = files  \n",
    "        self.behaviour_context_length = behaviour_context_length\n",
    "        self.all_dense_perc = all_dense_perc\n",
    "        self.future_window = future_window\n",
    "        self.max_positives = max_positives\n",
    "        self.negatives = negatives\n",
    "        self.batch_size = batch_size\n",
    "        self.global_negs = torch.randint(0, len(catalog_id_index), (behaviour_context_length, negatives))\n",
    "        self.rand_inbatch_negs = np.random.randint(0, self.max_positives * self.batch_size, (self.negatives,))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files) * 100000 // self.batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        if worker_info is None:\n",
    "            total_workers = 1\n",
    "            worker_id = 0\n",
    "        else:\n",
    "            total_workers = worker_info.num_workers\n",
    "            worker_id = worker_info.id\n",
    "        \n",
    "        for file in self.files[worker_id::total_workers]:\n",
    "            parr_data = pads.dataset(source=file.astype(str), format=\"parquet\")\n",
    "            for batch in parr_data.to_batches(batch_size=100000):\n",
    "                i = 0\n",
    "                df = batch.to_pandas()\n",
    "                df_size = df.shape[0]\n",
    "                while i < df_size:\n",
    "                    data = df[i:i + self.batch_size]\n",
    "                    batch_series = data.apply(lambda x: self.create_seq(x.interaction_list), axis=1)\n",
    "                    __batch_size = len(data)\n",
    "                    batch_random = torch.randint(1, 10000, (1,))\n",
    "                    global_negs = (self.global_negs * batch_random) % (catalog_id_vocab_size - 2) + 2\n",
    "                    global_negs = global_negs.unsqueeze(0).tile((__batch_size, 1, 1))\n",
    "\n",
    "                    batch_series_dict = {\n",
    "                        \"_positives\": np.concatenate(batch_series.map(lambda x: x['_positives']).to_list(), axis=0),\n",
    "                        \"_len_pos\": np.array(batch_series.map(lambda x: x['_len_pos']).to_list())\n",
    "                    }\n",
    "\n",
    "                    inbatch_negs = self.generate_inbatch_negatives(batch_series_dict, __batch_size)\n",
    "                    negatives = torch.cat((inbatch_negs, global_negs), dim=-1)\n",
    "\n",
    "                    selection_indices = torch.tensor(np.array(batch_series.map(lambda x: x['selection_indices']).to_list()), dtype=torch.long)\n",
    "                    batch_indices = torch.arange(selection_indices.shape[0]).view(-1, 1)\n",
    "                    negatives = negatives[batch_indices, selection_indices, :]\n",
    "\n",
    "                    yield {\n",
    "                        \"behaviour_seq\": torch.tensor(np.array(batch_series.map(lambda x: x['behaviour_seq']).to_list()), dtype=torch.long),\n",
    "                        \"event_type_seq\": torch.tensor(np.array(batch_series.map(lambda x: x['event_type_seq']).to_list()), dtype=torch.long),\n",
    "                        \"event_time_seq\": torch.tensor(np.array(batch_series.map(lambda x: x['event_time_seq']).to_list()), dtype=torch.long),\n",
    "                        \"positives\": torch.tensor(np.array(batch_series.map(lambda x: x['positives']).to_list()), dtype=torch.long),\n",
    "                        \"mask\": torch.tensor(np.array(batch_series.map(lambda x: x['mask']).to_list()), dtype=torch.bool),\n",
    "                        \"selection_indices\": selection_indices,\n",
    "                        \"negatives\": negatives\n",
    "                    }\n",
    "\n",
    "                    i = i + self.batch_size\n",
    "    \n",
    "    def create_seq(self, interaction_seq):\n",
    "        event_times = [datetime.datetime.fromtimestamp(ele['event_time'] / 1000000000) for ele in interaction_seq]\n",
    "        end_time = event_times[-1]\n",
    "        start_time = end_time - datetime.timedelta(days=self.future_window)\n",
    "        all_event = [event for event in interaction_seq if datetime.datetime.fromtimestamp(event['event_time'] / 1000000000) < start_time]\n",
    "        all_event = all_event[-1 * int(self.behaviour_context_length):]\n",
    "\n",
    "        catalog_id_seq = np.array([catalog_id_index.get(event['catalog_id'], catalog_id_index['<MASK>']) for event in all_event])\n",
    "        event_type_seq = np.array([event_type_index[event['event_type']] for event in all_event])\n",
    "        event_time_seq = np.array([event['event_time'] / 1000000000 for event in all_event])\n",
    "\n",
    "        mask = np.zeros(len(catalog_id_seq), dtype=bool)\n",
    "        num_positives = min(int(len(catalog_id_seq) * self.all_dense_perc), self.max_positives - 1)\n",
    "        mask[:num_positives] = True\n",
    "        np.random.shuffle(mask)\n",
    "        mask[-1] = True\n",
    "        num_masking = np.sum(mask)\n",
    "\n",
    "        all_positives = np.array([catalog_id_index.get(event['catalog_id'], catalog_id_index['<MASK>']) for event in interaction_seq if datetime.datetime.fromtimestamp(event['event_time'] / 1000000000) >= start_time])\n",
    "\n",
    "        _positives = all_positives[np.random.randint(0, len(all_positives), num_masking)]\n",
    "\n",
    "        seq_len = len(catalog_id_seq)\n",
    "\n",
    "        if seq_len < self.behaviour_context_length:\n",
    "            pad_num = self.behaviour_context_length - seq_len\n",
    "            catalog_id_seq = np.pad(catalog_id_seq, (pad_num, 0))\n",
    "            event_type_seq = np.pad(event_type_seq, (pad_num, 0))\n",
    "            mask = np.pad(mask, (pad_num, 0))\n",
    "            event_time_seq = np.pad(event_time_seq, (pad_num, 0))\n",
    "\n",
    "        positive_pad_num = self.max_positives - num_masking\n",
    "        selection_indices = np.pad(np.where(mask == 1)[0], (positive_pad_num, 0))\n",
    "        positives = np.pad(_positives, (positive_pad_num, 0))\n",
    "            \n",
    "        return {\n",
    "            \"behaviour_seq\": catalog_id_seq, \n",
    "            \"event_type_seq\": event_type_seq,\n",
    "            \"event_time_seq\": event_time_seq,\n",
    "            \"selection_indices\": selection_indices,\n",
    "            \"positives\": positives,\n",
    "            \"mask\": mask,\n",
    "            \"_positives\": _positives,\n",
    "            \"_len_pos\": num_masking,\n",
    "        }\n",
    "\n",
    "    def generate_inbatch_negatives(self, batch, _batch_size):\n",
    "        _positives = batch['_positives']\n",
    "        _lens = batch['_len_pos']\n",
    "        batch_size = _batch_size  \n",
    "    \n",
    "        inbatch_negs_num = self.negatives\n",
    "        inbatch_negs = np.zeros((batch_size, inbatch_negs_num))\n",
    "        \n",
    "        start = 0\n",
    "        indices = np.arange(len(_positives))\n",
    "        for i in range(batch_size):\n",
    "            exclude_range = np.delete(indices, np.arange(start, start + _lens[i]))\n",
    "            exclude_range_len = len(exclude_range)\n",
    "            inbatch_negs[i] = _positives[exclude_range][self.rand_inbatch_negs % exclude_range_len]\n",
    "            start += _lens[i]\n",
    "\n",
    "        inbatch_negs = torch.tensor(inbatch_negs, dtype=torch.long).unsqueeze(1).tile((1, self.behaviour_context_length, 1))\n",
    "\n",
    "        return inbatch_negs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48ff8ac2-f277-4748-bcb5-994e5f00870e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class PinnerFormerDataset(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_files, val_files, behaviour_context_length, all_dense_perc, future_window, max_positives, negatives, batch_size, num_workers):\n",
    "        super().__init__()\n",
    "        self.train_files = train_files  \n",
    "        self.val_files = val_files  \n",
    "        self.behaviour_context_length = behaviour_context_length\n",
    "        self.all_dense_perc = all_dense_perc\n",
    "        self.future_window = future_window\n",
    "        self.max_positives = max_positives\n",
    "        self.negatives = negatives\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if self.trainer:\n",
    "            start = self.trainer.global_rank\n",
    "            step = self.trainer.world_size\n",
    "        else:\n",
    "            start = 0\n",
    "            step = 1\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_set = SeqDataSet(\n",
    "                self.train_files[start::step],\n",
    "                self.behaviour_context_length,\n",
    "                self.all_dense_perc,\n",
    "                self.future_window,\n",
    "                self.max_positives,\n",
    "                self.negatives,\n",
    "                self.batch_size,\n",
    "\n",
    "            )\n",
    "\n",
    "            self.val_set = SeqDataSet(\n",
    "                self.val_files[start::step],\n",
    "                self.behaviour_context_length,\n",
    "                self.all_dense_perc,\n",
    "                self.future_window,\n",
    "                self.max_positives,\n",
    "                self.negatives,\n",
    "                self.batch_size,\n",
    "            )\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True, persistent_workers=True, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False, persistent_workers=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37fc1502-3d57-4a6d-b937-8915c72e3771",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# mask = np.zeros(10, dtype=bool)\n",
    "# num_positives = min(4,8)\n",
    "# mask[:num_positives] = True\n",
    "# np.random.shuffle(mask)\n",
    "# mask[-1]=True\n",
    "# num_masking = np.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82d6bcd6-acdc-406b-a6c7-b0910e7c1204",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# behaviour_context_length = 1500\n",
    "# all_dense_perc = 0.5\n",
    "# future_window = 28\n",
    "# max_positives = 640\n",
    "# negatives = 1000\n",
    "# batch_size = 512\n",
    "# num_workers = 1\n",
    "# ds = SeqDataSet(train_files, behaviour_context_length, all_dense_perc, future_window, max_positives, negatives, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c5ae075-557b-4761-bf6c-c4b60cefefdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# batch_data = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59d877b6-0b3a-4b29-93fe-f3cea76b89ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dataset = PinnerFormerDataset(train_files, val_files, behaviour_context_length, all_dense_perc, future_window, max_positives, negatives, batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29a19d43-44b1-4637-8ddb-f7514f92d0fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dataset.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a106af2-e816-4c7b-b5a2-74393fe64500",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# next(iter(dataset.train_dataloader()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdd98d06-1042-4042-a48b-9cf0c4cd00a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fad798c2-2d45-4f09-823a-4e025fe5acd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class CatalogEmbedding(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        catalog_id_vocab_size,\n",
    "        embedding_dim,\n",
    "        use_pretrained=False,\n",
    "        pretrained_weights=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.catalog_id_vocab_size = catalog_id_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.catalog_embedding = nn.Embedding(num_embeddings=catalog_id_vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        if use_pretrained and pretrained_weights is not None:\n",
    "            self.catalog_embedding.weight = nn.Parameter(pretrained_weights, requires_grad=False)\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.catalog_embedding(X)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "081bfd9e-8df0-4c3c-aca3-092904e64910",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class UserTower(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_layers,\n",
    "                 nhead,\n",
    "                 behaviour_context_length,\n",
    "                 embedding_dim,\n",
    "                 event_type_vocab_size\n",
    "                ):\n",
    "        super(UserTower, self).__init__()\n",
    "\n",
    "        self.nhead = nhead\n",
    "        dropout_perc = 0.3 \n",
    "        self.behaviour_context_length = behaviour_context_length\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Event type embedding\n",
    "        self.event_type_embedding = nn.Embedding(event_type_vocab_size, embedding_dim)\n",
    "        num_features = 2\n",
    "        time_features = 0\n",
    "        self.input_dim = num_features * embedding_dim + time_features\n",
    "\n",
    "        # Transformer layers\n",
    "        self.dropout = nn.Dropout(dropout_perc)\n",
    "        self.norm = nn.LayerNorm(embedding_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(embedding_dim, nhead=nhead, batch_first=True, dropout=dropout_perc, norm_first=True)\n",
    "        self.tf_encoder = nn.TransformerEncoder(encoder_layer, num_layers, norm=self.norm)\n",
    "\n",
    "        # MLP head\n",
    "        self.mlp_extract = nn.Linear(self.input_dim, embedding_dim)\n",
    "\n",
    "        self.mlp_out = nn.Sequential(\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "            nn.Linear(embedding_dim, 4 * embedding_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * embedding_dim, embedding_dim),\n",
    "            nn.LayerNorm(embedding_dim)\n",
    "        )\n",
    "\n",
    "        self.future_mask = torch.triu(torch.ones(self.behaviour_context_length, self.behaviour_context_length, dtype=torch.bool), diagonal=1)\n",
    "        self.register_buffer('future_mask_const', self.future_mask)\n",
    "        self.register_buffer('seq_diag_const', ~torch.diag(torch.ones(self.behaviour_context_length, dtype=torch.bool)))\n",
    "\n",
    "        div_term = torch.exp(torch.arange(0, embedding_dim, 2) * -(torch.log(torch.tensor(10000.0)) / embedding_dim))\n",
    "        self.register_buffer('div_term', div_term)\n",
    "\n",
    "    def merge_attn_masks(self, X):\n",
    "        batch_size = X[\"behaviour_seq\"].shape[0]\n",
    "        seq_len = X[\"behaviour_seq\"].shape[1]\n",
    "\n",
    "        padding = (X[\"behaviour_seq\"] == 0)\n",
    "        masking = (X[\"behaviour_seq\"] == 1)\n",
    "        padding_mask = padding.logical_or(masking)\n",
    "\n",
    "        padding_mask_broadcast = padding_mask.bool().unsqueeze(1)\n",
    "        future_masks = torch.tile(self.future_mask_const[:seq_len, :seq_len], (batch_size, 1, 1))\n",
    "\n",
    "        merged_masks = torch.logical_or(padding_mask_broadcast, future_masks)\n",
    "        \n",
    "        diag_masks = torch.tile(self.seq_diag_const[:seq_len, :seq_len], (batch_size * self.nhead, 1, 1))\n",
    "        multi_head_mask = torch.tile(merged_masks.unsqueeze(1), (1, self.nhead, 1, 1)).reshape((-1, seq_len, seq_len))\n",
    "        \n",
    "        return torch.logical_and(diag_masks, multi_head_mask)\n",
    "\n",
    "    def positional_encoding(self, timestamps, embedding_dim=16):\n",
    "        pe = torch.stack((torch.sin(timestamps.unsqueeze(-1) * self.div_term), torch.cos(timestamps.unsqueeze(-1) * self.div_term)), dim=-1).flatten(start_dim=-2)\n",
    "        return pe\n",
    "\n",
    "    def forward(self, X, catalog_embedding):\n",
    "        pe = self.positional_encoding(X['event_time_seq'], embedding_dim=self.embedding_dim)\n",
    "\n",
    "        x = torch.cat((\n",
    "            catalog_embedding(X['behaviour_seq']), \n",
    "            self.event_type_embedding(X['event_type_seq'])\n",
    "        ), dim=-1)\n",
    "\n",
    "        x = self.mlp_extract(x) + pe\n",
    "\n",
    "        attn_mask = self.merge_attn_masks(X)\n",
    "\n",
    "        x = self.tf_encoder(x, mask=attn_mask)\n",
    "\n",
    "        batch_indices = torch.arange(X['selection_indices'].shape[0]).view(-1, 1)\n",
    "        x = x[batch_indices, X['selection_indices'], :]\n",
    "\n",
    "        x = self.mlp_out(x)\n",
    "\n",
    "        x = F.normalize(x, p=2, dim=-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3afd4f8f-515b-401f-b70b-b20e8efdb02e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class CatalogTower(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(CatalogTower, self).__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "            nn.Linear(embedding_dim, 4 * embedding_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * embedding_dim, embedding_dim),\n",
    "            nn.LayerNorm(embedding_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, catalog_embedding):\n",
    "        x = catalog_embedding(x)\n",
    "        x = self.mlp(x)\n",
    "        x = F.normalize(x, p=2, dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce623b7d-07fd-472b-891d-c569177f5295",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# class PinnerFormer(pl.LightningModule):\n",
    "#     def __init__(self, user_tower, catalog_tower, catalog_embedding, batch_size, max_positives):\n",
    "#         super().__init__()\n",
    "#         self.user_tower = user_tower\n",
    "#         self.catalog_tower = catalog_tower\n",
    "#         self.catalog_embedding = catalog_embedding\n",
    "#         self.criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "#         self.lr = 0.001\n",
    "#         self.temperature = 0.1\n",
    "#         self.max_positives = max_positives\n",
    "#         self.register_buffer('pos_labels', torch.ones((batch_size*max_positives), dtype=torch.long))\n",
    "    \n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         batch_size = batch['behaviour_seq'].shape[0]\n",
    "#         context_length = batch['behaviour_seq'].shape[1]\n",
    "        \n",
    "#         catalog_embeddings = self.catalog_embedding(batch['behaviour_seq'])\n",
    "#         user_embedding = self.user_tower(batch, self.catalog_embedding)\n",
    "\n",
    "#         candidates = torch.cat([batch['positives'].unsqueeze(-1), batch['negatives']], dim=-1)\n",
    "#         candidates_embedding = self.catalog_tower(candidates, self.catalog_embedding)\n",
    "    \n",
    "#         loss = self.embedding_loss(batch, user_embedding, candidates_embedding)\n",
    "#         self.log('train_loss', loss.item(), on_step=True, on_epoch=True)\n",
    "        \n",
    "#         return loss\n",
    "        \n",
    "    \n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         batch_size = batch['behaviour_seq'].shape[0]\n",
    "#         context_length = batch['behaviour_seq'].shape[1]\n",
    "        \n",
    "#         catalog_embeddings = self.catalog_embedding(batch['behaviour_seq'])\n",
    "#         user_embedding = self.user_tower(batch, self.catalog_embedding)\n",
    "\n",
    "#         candidates = torch.cat([batch['positives'].unsqueeze(-1), batch['negatives']], dim=-1)\n",
    "#         candidates_embedding = self.catalog_tower(candidates, self.catalog_embedding)\n",
    "    \n",
    "#         loss = self.embedding_loss(batch, user_embedding, candidates_embedding)\n",
    "#         self.log('val_loss', loss.item(), on_step=True, on_epoch=True)\n",
    "    \n",
    "#     def configure_optimizers(self):\n",
    "#        optimizer = torch.optim.AdamW([\n",
    "#            {\"params\": self.user_tower.parameters()}, \n",
    "#            {\"params\": self.catalog_tower.parameters()},\n",
    "#            {\"params\": self.catalog_embedding.parameters()}\n",
    "#         ], lr=self.lr)        \n",
    "#        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "       \n",
    "#        return {\n",
    "#             'optimizer': optimizer,\n",
    "#             'lr_scheduler': {\n",
    "#                 'scheduler': scheduler,\n",
    "#                 'interval': 'step',\n",
    "#                 'frequency': 500, \n",
    "#                 \"name\": 'lr'\n",
    "#             }\n",
    "#         }\n",
    "    \n",
    "#     def embedding_loss(self, batch, user_embedding, candidates_embedding):\n",
    "#         scores = torch.matmul(user_embedding.unsqueeze(2), candidates_embedding.transpose(-2, -1)).squeeze(-2)\n",
    "#         scores = scores.reshape((-1, scores.shape[-1])) / self.temperature\n",
    "#         non_padding = (batch[\"positives\"] != 0).logical_or(batch[\"positives\"] != 1).reshape(-1)\n",
    "#         loss = (self.criterion(scores, self.pos_labels[:batch[\"positives\"].shape[0]*self.max_positives]) * non_padding).sum() / non_padding.sum()\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35e0cde0-63bf-4863-8dcb-6dd3ec0296df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class PinnerFormer(pl.LightningModule):\n",
    "    def __init__(self, user_tower, catalog_tower, catalog_embedding, batch_size, max_positives):\n",
    "        super().__init__()\n",
    "        self.user_tower = user_tower\n",
    "        self.catalog_tower = catalog_tower\n",
    "        self.catalog_embedding = catalog_embedding\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "        self.lr = 0.001\n",
    "        self.temperature = 0.1\n",
    "        self.max_positives = max_positives\n",
    "        self.register_buffer('pos_labels', torch.ones((batch_size * max_positives), dtype=torch.long))\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch_size = batch['behaviour_seq'].shape[0]\n",
    "        context_length = batch['behaviour_seq'].shape[1]\n",
    "        \n",
    "        catalog_embeddings = self.catalog_embedding(batch['behaviour_seq'])\n",
    "        user_embedding = self.user_tower(batch, self.catalog_embedding)\n",
    "\n",
    "        candidates = torch.cat([batch['positives'].unsqueeze(-1), batch['negatives']], dim=-1)\n",
    "        candidates_embedding = self.catalog_tower(candidates, self.catalog_embedding)\n",
    "    \n",
    "        loss = self.embedding_loss(batch, user_embedding, candidates_embedding)\n",
    "\n",
    "        self.log('train_loss', loss.item(), rank_zero_only=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        batch_size = batch['behaviour_seq'].shape[0]\n",
    "        context_length = batch['behaviour_seq'].shape[1]\n",
    "        \n",
    "        catalog_embeddings = self.catalog_embedding(batch['behaviour_seq'])\n",
    "        user_embedding = self.user_tower(batch, self.catalog_embedding)\n",
    "\n",
    "        candidates = torch.cat([batch['positives'].unsqueeze(-1), batch['negatives']], dim=-1)\n",
    "        candidates_embedding = self.catalog_tower(candidates, self.catalog_embedding)\n",
    "    \n",
    "        loss = self.embedding_loss(batch, user_embedding, candidates_embedding)\n",
    "\n",
    "        self.log('val_loss', loss.item(), rank_zero_only=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {\"params\": self.user_tower.parameters()}, \n",
    "            {\"params\": self.catalog_tower.parameters()},\n",
    "            {\"params\": self.catalog_embedding.parameters()}\n",
    "        ], lr=self.lr)        \n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9, verbose=True, last_epoch=-1)\n",
    "       \n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'step',\n",
    "                'frequency': 500, \n",
    "                \"name\": 'lr'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def cosine_sim(self, a, b, eps=1e-8):\n",
    "        a_n, b_n = a.norm(dim=-1).unsqueeze(-1), b.norm(dim=-1).unsqueeze(-1)\n",
    "        a_norm = a / torch.clamp(a_n, min=eps)\n",
    "        b_norm = b / torch.clamp(b_n, min=eps)\n",
    "        sim_mt = torch.matmul(a_norm.unsqueeze(2), b_norm.transpose(-2, -1)).squeeze(2)\n",
    "        return sim_mt\n",
    "\n",
    "    def embedding_loss(self, batch, user_embedding, candidates_embedding):\n",
    "        scores = self.cosine_sim(user_embedding.unsqueeze(2), candidates_embedding.transpose(-2, -1)).squeeze(-2)\n",
    "        scores = scores.reshape((-1, scores.shape[-1])) / self.temperature\n",
    "        non_padding = (batch[\"positives\"] != 0).logical_or(batch[\"positives\"] != 1).reshape(-1)\n",
    "        loss = (self.criterion(scores, self.pos_labels[:batch[\"positives\"].shape[0] * self.max_positives]) * non_padding).sum() / non_padding.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e58719e-369b-4055-b438-eb1d83b6ca0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# catalog_embedding = CatalogEmbedding(catalog_id_vocab_size,embedding_dim)\n",
    "\n",
    "# user_tower = UserTower(\n",
    "#     num_layers,\n",
    "#     nhead,\n",
    "#     behaviour_context_length,\n",
    "#     embedding_dim,\n",
    "#     event_type_vocab_size\n",
    "# )\n",
    "\n",
    "# catalog_tower = CatalogTower(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4c0ac25-2412-42e5-b01b-3aba455ed304",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# x = user_tower(batch_data,catalog_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54eba15d-6e30-4ad4-8d8d-ab4ff860873b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87105ea1-aca6-40a3-bb64-4baeb465ccfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/20 11:22:28 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    }
   ],
   "source": [
    "db_host = dbutils.notebook.entry_point.getDbutils().notebook().getContext().extraContext().apply('api_url')\n",
    "db_token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "username = 'arshi.khan@meesho.com'\n",
    "experiment_path = f'/Users/{username}/long-term-embedding'\n",
    "experiment_id = mlflow.set_experiment(experiment_path).experiment_id\n",
    "mlflow.start_run(experiment_id = experiment_id, log_system_metrics=True)\n",
    "mlflow.set_tag(key='model',value='transformer')\n",
    "run_id = mlflow.active_run().info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5158eaee-10b2-474a-8c0e-384faa51ce9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d3c526a-6c93-447e-b4d6-53a4839e5159",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    # data params \n",
    "    \"checkpoint_version\": \"v9.1\",\n",
    "    \"index_path\": \"long_term_user_emb/indexes/v9/\",\n",
    "    \"filtered_journeys_path\": \"long_term_user_emb/user_seq_final/v9/\",\n",
    "    \"checkpoint_path\": \"gs://gcs-dsci-fryou-fy-dev-prd/long_term_user_emb/checkpoint_dir/v9.1/\",\n",
    "\n",
    "    # dataset params\n",
    "    \"behaviour_context_length\": 1000,\n",
    "    \"all_dense_perc\": 0.15,\n",
    "    \"future_window\": 14,\n",
    "    \"max_positives\": 64,\n",
    "    \"negatives\": 10,\n",
    "    \"batch_size\": 2,\n",
    "    \"num_workers\": 1,\n",
    "\n",
    "    # model params\n",
    "    \"embedding_dim\": 16,\n",
    "    \"num_layers\": 2,\n",
    "    \"nhead\": 2,\n",
    "\n",
    "    # training params \n",
    "    \"max_epochs\": 100,\n",
    "    \"limit_val_batches\": -1,\n",
    "    \"limit_train_batches\": 5000,\n",
    "    \"val_check_interval\": 500,\n",
    "    \"overfit_batches\": 1,\n",
    "    \"log_every_n_steps\": 1,\n",
    "    \"accelerator\": \"gpu\",\n",
    "    \"num_gpu\": 1,\n",
    "    \"num_nodes\": 1,\n",
    "    \"num_sanity_val_steps\": 0\n",
    "}\n",
    "\n",
    "# config = {\n",
    "#     # data params \n",
    "#     \"checkpoint_version\": \"v10.1\",\n",
    "#     \"index_path\": \"long_term_user_emb/indexes/v10/\",\n",
    "#     \"filtered_journeys_path\": \"long_term_user_emb/user_seq_final/v10/\",\n",
    "#     \"checkpoint_path\": \"gs://gcs-dsci-fryou-fy-dev-prd/long_term_user_emb/checkpoint_dir/v10.1/\",\n",
    "\n",
    "#     # dataset params\n",
    "#     \"behaviour_context_length\": 1000,\n",
    "#     \"all_dense_perc\": 0.15,\n",
    "#     \"future_window\": 14,\n",
    "#     \"max_positives\": 64,\n",
    "#     \"negatives\": 500,\n",
    "#     \"batch_size\": 64,\n",
    "#     \"num_workers\": 8,\n",
    "\n",
    "#     # model params\n",
    "#     \"embedding_dim\": 32,\n",
    "#     \"num_layers\": 2,\n",
    "#     \"nhead\": 2,\n",
    "\n",
    "#     # training params \n",
    "#     \"max_epochs\": 1,\n",
    "#     \"limit_val_batches\": 0,\n",
    "#     \"limit_train_batches\": 5000,\n",
    "#     \"val_check_interval\": 500,\n",
    "#     \"overfit_batches\": 0,\n",
    "#     \"log_every_n_steps\": 50,\n",
    "#     \"accelerator\": \"gpu\",\n",
    "#     \"num_gpu\": 1,\n",
    "#     \"num_nodes\": 1,\n",
    "#     \"num_sanity_val_steps\": 2\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d717860-93f7-4533-9721-46bd000d9358",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config['num_gpu'] = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "512d2725-7ee5-456f-a24d-f7c96d418c7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90af6b34-a5e4-4bc3-ace4-948b610a033a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'long_term_user_emb/user_seq_final/v9/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"filtered_journeys_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5adcae97-92a8-4df0-9b67-b805c0e725b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total files inside fn:  154\nvalue of end inside fn:  152\nnum train files:148, num val files:4\n"
     ]
    }
   ],
   "source": [
    "files = [ele.name for ele in bucket.list_blobs(prefix=config[\"filtered_journeys_path\"]) if 'parquet' in ele.name]  \n",
    "files = [f\"gs://gcs-dsci-fryou-fy-dev-prd/{ele}\" for ele in files]\n",
    "files = np.array(files).astype(np.string_)\n",
    "\n",
    "WORLD_SIZE = config[\"num_nodes\"] if config[\"num_gpu\"] == 0 else config[\"num_gpu\"] * config[\"num_nodes\"]\n",
    "\n",
    "files = get_equally_distributed_files(files,WORLD_SIZE)\n",
    "train_files = files[:-1*WORLD_SIZE]\n",
    "val_files = files[-1*WORLD_SIZE:]\n",
    "print(f\"num train files:{len(train_files)}, num val files:{len(val_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bfbdad5-b796-474e-aa90-e297bb2ccc28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [rank: 0] Seed set to 42\nINFO:lightning.fabric.utilities.seed:[rank: 0] Seed set to 42\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catalog vocab size:8.40019 M\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42, workers=True)\n",
    "SPECIAl_TOKENS = {\n",
    "    \"<PAD>\":0,\n",
    "    \"<MASK>\":1\n",
    "}\n",
    "\n",
    "event_type_index, event_type_vocab_size = get_index(config[\"index_path\"], \"event_type\", SPECIAl_TOKENS)\n",
    "catalog_id_index, catalog_id_vocab_size = get_index(config[\"index_path\"], \"catalog_id\", SPECIAl_TOKENS)\n",
    "\n",
    "print(f\"catalog vocab size:{catalog_id_vocab_size/1000000} M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "833ff6f5-c798-4cd4-9621-75d0b4bfaa0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Init Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa8ac547-1b9e-45de-b09f-ffefe71be6ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset = PinnerFormerDataset(\n",
    "    train_files,\n",
    "    val_files,\n",
    "    config[\"behaviour_context_length\"],\n",
    "    config[\"all_dense_perc\"],\n",
    "    config[\"future_window\"],\n",
    "    config[\"max_positives\"],\n",
    "    config[\"negatives\"],\n",
    "    config[\"batch_size\"],\n",
    "    config[\"num_workers\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01a13561-3401-47c4-a5fb-4134a7d0f6b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dataset.setup(\"fit\")\n",
    "# batch_data = next(iter(dataset.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfdf00b9-61eb-46a9-97f4-1c64c0d602f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_embedding = CatalogEmbedding(catalog_id_vocab_size,config[\"embedding_dim\"])\n",
    "\n",
    "user_tower = UserTower(\n",
    "    config[\"num_layers\"],\n",
    "    config[\"nhead\"],\n",
    "    config[\"behaviour_context_length\"],\n",
    "    config[\"embedding_dim\"],\n",
    "    event_type_vocab_size\n",
    ")\n",
    "catalog_tower = CatalogTower(config[\"embedding_dim\"])\n",
    "\n",
    "model = PinnerFormer(user_tower, catalog_tower, catalog_embedding, config[\"batch_size\"], config[\"max_positives\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74b25cc1-b7be-452e-85f0-73d2d743da54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Trainer Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b8c1b0c-47f5-4f15-8825-44dfbfcbb05c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(experiment_path)\n",
    "mlf_logger = pl.loggers.MLFlowLogger(experiment_name=experiment_path, run_id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ca5869a-62ae-4ed9-96eb-f87f71ffaec6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\nINFO: Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\nINFO:lightning.pytorch.utilities.rank_zero:Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\nINFO: Using 16bit Automatic Mixed Precision (AMP)\nINFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\nINFO: GPU available: True (cuda), used: True\nINFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\nINFO: IPU available: False, using: 0 IPUs\nINFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\nINFO: HPU available: False, using: 0 HPUs\nINFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\nINFO: `Trainer(overfit_batches=1)` was configured so 1 batch will be used.\nINFO:lightning.pytorch.utilities.rank_zero:`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    precision=16,\n",
    "    max_epochs=config[\"max_epochs\"],\n",
    "    limit_val_batches=config[\"limit_val_batches\"],\n",
    "    limit_train_batches=config[\"limit_train_batches\"],\n",
    "    val_check_interval = config[\"val_check_interval\"],\n",
    "    overfit_batches=config[\"overfit_batches\"],\n",
    "    log_every_n_steps = config[\"log_every_n_steps\"],\n",
    "    check_val_every_n_epoch=None,\n",
    "    accelerator=config[\"accelerator\"],\n",
    "    strategy=\"auto\",\n",
    "    logger=mlf_logger,\n",
    "    num_sanity_val_steps = config[\"num_sanity_val_steps\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99411bf3-6a2d-4249-88c3-4c9d7c2a610d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\nINFO:lightning.pytorch.utilities.rank_zero:You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\nINFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\nINFO: \n  | Name              | Type             | Params\n-------------------------------------------------------\n0 | user_tower        | UserTower        | 140 K \n1 | catalog_tower     | CatalogTower     | 2.2 K \n2 | catalog_embedding | CatalogEmbedding | 134 M \n3 | criterion         | CrossEntropyLoss | 0     \n-------------------------------------------------------\n134 M     Trainable params\n0         Non-trainable params\n134 M     Total params\n538.182   Total estimated model params size (MB)\nINFO:lightning.pytorch.callbacks.model_summary:\n  | Name              | Type             | Params\n-------------------------------------------------------\n0 | user_tower        | UserTower        | 140 K \n1 | catalog_tower     | CatalogTower     | 2.2 K \n2 | catalog_embedding | CatalogEmbedding | 134 M \n3 | criterion         | CrossEntropyLoss | 0     \n-------------------------------------------------------\n134 M     Trainable params\n0         Non-trainable params\n134 M     Total params\n538.182   Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\nAdjusting learning rate of group 1 to 1.0000e-03.\nAdjusting learning rate of group 2 to 1.0000e-03.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-720585262727022>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n",
       "\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n",
       "\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
       "\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n",
       "\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n",
       "\u001B[1;32m    576\u001B[0m     ckpt_path,\n",
       "\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m    579\u001B[0m )\n",
       "\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n",
       "\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n",
       "\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n",
       "\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[0;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n",
       "\u001B[1;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m   1031\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n",
       "\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n",
       "\u001B[0;32m-> 1033\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:197\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip:\n",
       "\u001B[1;32m    199\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:225\u001B[0m, in \u001B[0;36m_FitLoop.setup_data\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    222\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: resetting train dataloader\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    224\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_source\n",
       "\u001B[0;32m--> 225\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m \u001B[43m_request_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    226\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_dataloader()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(train_dataloader, CombinedLoader):\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:342\u001B[0m, in \u001B[0;36m_request_dataloader\u001B[0;34m(data_source)\u001B[0m\n",
       "\u001B[1;32m    331\u001B[0m \u001B[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001B[39;00m\n",
       "\u001B[1;32m    332\u001B[0m \n",
       "\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n",
       "\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    The requested dataloader\u001B[39;00m\n",
       "\u001B[1;32m    335\u001B[0m \n",
       "\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _replace_dunder_methods(DataLoader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m), _replace_dunder_methods(BatchSampler):\n",
       "\u001B[1;32m    338\u001B[0m     \u001B[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001B[39;00m\n",
       "\u001B[1;32m    339\u001B[0m     \u001B[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001B[39;00m\n",
       "\u001B[1;32m    340\u001B[0m     \u001B[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001B[39;00m\n",
       "\u001B[1;32m    341\u001B[0m     \u001B[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001B[39;00m\n",
       "\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata_source\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:309\u001B[0m, in \u001B[0;36m_DataLoaderSource.dataloader\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance, pl\u001B[38;5;241m.\u001B[39mLightningDataModule):\n",
       "\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_datamodule_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:179\u001B[0m, in \u001B[0;36m_call_lightning_datamodule_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(fn):\n",
       "\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningDataModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mdatamodule\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n",
       "\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m<command-720585262726990>, line 45\u001B[0m, in \u001B[0;36mPinnerFormerDataset.train_dataloader\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_dataloader\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n",
       "\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersistent_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/fabric/utilities/data.py:324\u001B[0m, in \u001B[0;36m_wrap_init_method.<locals>.wrapper\u001B[0;34m(obj, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m store_explicit_arg \u001B[38;5;129;01min\u001B[39;00m kwargs:\n",
       "\u001B[1;32m    322\u001B[0m         \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstore_explicit_arg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, kwargs[store_explicit_arg])\n",
       "\u001B[0;32m--> 324\u001B[0m \u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__pl_inside_init\u001B[39m\u001B[38;5;124m\"\u001B[39m, old_inside_init)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:307\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n",
       "\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.\u001B[39;00m\n",
       "\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m shuffle \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m}:\n",
       "\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    309\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshuffle option, but got shuffle=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shuffle))\n",
       "\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sampler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# See NOTE [ Custom Samplers and IterableDataset ]\u001B[39;00m\n",
       "\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    314\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    315\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampler option, but got sampler=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sampler))\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ValueError</span>: DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-720585262727022>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    576\u001B[0m     ckpt_path,\n\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    579\u001B[0m )\n\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1031\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m-> 1033\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:197\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip:\n\u001B[1;32m    199\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:225\u001B[0m, in \u001B[0;36m_FitLoop.setup_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    222\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: resetting train dataloader\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    224\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_source\n\u001B[0;32m--> 225\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m \u001B[43m_request_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_dataloader()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(train_dataloader, CombinedLoader):\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:342\u001B[0m, in \u001B[0;36m_request_dataloader\u001B[0;34m(data_source)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \n\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    The requested dataloader\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _replace_dunder_methods(DataLoader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m), _replace_dunder_methods(BatchSampler):\n\u001B[1;32m    338\u001B[0m     \u001B[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001B[39;00m\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001B[39;00m\n\u001B[1;32m    340\u001B[0m     \u001B[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001B[39;00m\n\u001B[1;32m    341\u001B[0m     \u001B[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001B[39;00m\n\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata_source\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:309\u001B[0m, in \u001B[0;36m_DataLoaderSource.dataloader\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance, pl\u001B[38;5;241m.\u001B[39mLightningDataModule):\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_datamodule_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:179\u001B[0m, in \u001B[0;36m_call_lightning_datamodule_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(fn):\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningDataModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mdatamodule\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
        "File \u001B[0;32m<command-720585262726990>, line 45\u001B[0m, in \u001B[0;36mPinnerFormerDataset.train_dataloader\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_dataloader\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersistent_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/fabric/utilities/data.py:324\u001B[0m, in \u001B[0;36m_wrap_init_method.<locals>.wrapper\u001B[0;34m(obj, *args, **kwargs)\u001B[0m\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m store_explicit_arg \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[1;32m    322\u001B[0m         \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstore_explicit_arg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, kwargs[store_explicit_arg])\n\u001B[0;32m--> 324\u001B[0m \u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__pl_inside_init\u001B[39m\u001B[38;5;124m\"\u001B[39m, old_inside_init)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:307\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.\u001B[39;00m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m shuffle \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m}:\n\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    309\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshuffle option, but got shuffle=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shuffle))\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sampler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# See NOTE [ Custom Samplers and IterableDataset ]\u001B[39;00m\n\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    314\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    315\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampler option, but got sampler=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sampler))\n",
        "\u001B[0;31mValueError\u001B[0m: DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "792c9706-7a2d-4628-8d76-5c12bddeeb8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "811bbee4-dcf0-4f41-954f-c24075d26d17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-720585262727022>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n",
       "\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n",
       "\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
       "\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n",
       "\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n",
       "\u001B[1;32m    576\u001B[0m     ckpt_path,\n",
       "\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m    579\u001B[0m )\n",
       "\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n",
       "\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n",
       "\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n",
       "\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[0;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n",
       "\u001B[1;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m   1031\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n",
       "\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n",
       "\u001B[0;32m-> 1033\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:197\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip:\n",
       "\u001B[1;32m    199\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:225\u001B[0m, in \u001B[0;36m_FitLoop.setup_data\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    222\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: resetting train dataloader\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    224\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_source\n",
       "\u001B[0;32m--> 225\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m \u001B[43m_request_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    226\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_dataloader()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(train_dataloader, CombinedLoader):\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:342\u001B[0m, in \u001B[0;36m_request_dataloader\u001B[0;34m(data_source)\u001B[0m\n",
       "\u001B[1;32m    331\u001B[0m \u001B[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001B[39;00m\n",
       "\u001B[1;32m    332\u001B[0m \n",
       "\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n",
       "\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    The requested dataloader\u001B[39;00m\n",
       "\u001B[1;32m    335\u001B[0m \n",
       "\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _replace_dunder_methods(DataLoader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m), _replace_dunder_methods(BatchSampler):\n",
       "\u001B[1;32m    338\u001B[0m     \u001B[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001B[39;00m\n",
       "\u001B[1;32m    339\u001B[0m     \u001B[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001B[39;00m\n",
       "\u001B[1;32m    340\u001B[0m     \u001B[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001B[39;00m\n",
       "\u001B[1;32m    341\u001B[0m     \u001B[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001B[39;00m\n",
       "\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata_source\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:309\u001B[0m, in \u001B[0;36m_DataLoaderSource.dataloader\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance, pl\u001B[38;5;241m.\u001B[39mLightningDataModule):\n",
       "\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_datamodule_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:179\u001B[0m, in \u001B[0;36m_call_lightning_datamodule_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(fn):\n",
       "\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningDataModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mdatamodule\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n",
       "\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m<command-720585262726990>, line 45\u001B[0m, in \u001B[0;36mPinnerFormerDataset.train_dataloader\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_dataloader\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n",
       "\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersistent_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/fabric/utilities/data.py:324\u001B[0m, in \u001B[0;36m_wrap_init_method.<locals>.wrapper\u001B[0;34m(obj, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m store_explicit_arg \u001B[38;5;129;01min\u001B[39;00m kwargs:\n",
       "\u001B[1;32m    322\u001B[0m         \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstore_explicit_arg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, kwargs[store_explicit_arg])\n",
       "\u001B[0;32m--> 324\u001B[0m \u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__pl_inside_init\u001B[39m\u001B[38;5;124m\"\u001B[39m, old_inside_init)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:307\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n",
       "\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.\u001B[39;00m\n",
       "\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m shuffle \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m}:\n",
       "\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    309\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshuffle option, but got shuffle=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shuffle))\n",
       "\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sampler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# See NOTE [ Custom Samplers and IterableDataset ]\u001B[39;00m\n",
       "\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    314\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    315\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampler option, but got sampler=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sampler))\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-720585262727022>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    576\u001B[0m     ckpt_path,\n\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    579\u001B[0m )\n\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1031\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m-> 1033\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:197\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip:\n\u001B[1;32m    199\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:225\u001B[0m, in \u001B[0;36m_FitLoop.setup_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    222\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: resetting train dataloader\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    224\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_source\n\u001B[0;32m--> 225\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m \u001B[43m_request_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_dataloader()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(train_dataloader, CombinedLoader):\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:342\u001B[0m, in \u001B[0;36m_request_dataloader\u001B[0;34m(data_source)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \n\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    The requested dataloader\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _replace_dunder_methods(DataLoader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m), _replace_dunder_methods(BatchSampler):\n\u001B[1;32m    338\u001B[0m     \u001B[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001B[39;00m\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001B[39;00m\n\u001B[1;32m    340\u001B[0m     \u001B[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001B[39;00m\n\u001B[1;32m    341\u001B[0m     \u001B[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001B[39;00m\n\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata_source\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:309\u001B[0m, in \u001B[0;36m_DataLoaderSource.dataloader\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance, pl\u001B[38;5;241m.\u001B[39mLightningDataModule):\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_datamodule_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:179\u001B[0m, in \u001B[0;36m_call_lightning_datamodule_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(fn):\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningDataModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mdatamodule\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
        "File \u001B[0;32m<command-720585262726990>, line 45\u001B[0m, in \u001B[0;36mPinnerFormerDataset.train_dataloader\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_dataloader\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersistent_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/fabric/utilities/data.py:324\u001B[0m, in \u001B[0;36m_wrap_init_method.<locals>.wrapper\u001B[0;34m(obj, *args, **kwargs)\u001B[0m\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m store_explicit_arg \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[1;32m    322\u001B[0m         \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstore_explicit_arg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, kwargs[store_explicit_arg])\n\u001B[0;32m--> 324\u001B[0m \u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__pl_inside_init\u001B[39m\u001B[38;5;124m\"\u001B[39m, old_inside_init)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:307\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.\u001B[39;00m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m shuffle \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m}:\n\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    309\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshuffle option, but got shuffle=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shuffle))\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sampler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# See NOTE [ Custom Samplers and IterableDataset ]\u001B[39;00m\n\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    314\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    315\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampler option, but got sampler=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sampler))\n",
        "\u001B[0;31mValueError\u001B[0m: DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "callback_checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "  dirpath=config[\"checkpoint_path\"], \n",
    "  filename='{epoch}-{step}-{val_loss_5:.2f}',\n",
    "  save_top_k = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e683091b-f7d5-4af0-92bf-9f74cacaa050",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-720585262727022>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n",
       "\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n",
       "\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
       "\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n",
       "\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n",
       "\u001B[1;32m    576\u001B[0m     ckpt_path,\n",
       "\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m    579\u001B[0m )\n",
       "\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n",
       "\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n",
       "\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n",
       "\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[0;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n",
       "\u001B[1;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m   1031\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n",
       "\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n",
       "\u001B[0;32m-> 1033\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:197\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip:\n",
       "\u001B[1;32m    199\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:225\u001B[0m, in \u001B[0;36m_FitLoop.setup_data\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    222\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: resetting train dataloader\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    224\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_source\n",
       "\u001B[0;32m--> 225\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m \u001B[43m_request_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    226\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_dataloader()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(train_dataloader, CombinedLoader):\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:342\u001B[0m, in \u001B[0;36m_request_dataloader\u001B[0;34m(data_source)\u001B[0m\n",
       "\u001B[1;32m    331\u001B[0m \u001B[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001B[39;00m\n",
       "\u001B[1;32m    332\u001B[0m \n",
       "\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n",
       "\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    The requested dataloader\u001B[39;00m\n",
       "\u001B[1;32m    335\u001B[0m \n",
       "\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _replace_dunder_methods(DataLoader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m), _replace_dunder_methods(BatchSampler):\n",
       "\u001B[1;32m    338\u001B[0m     \u001B[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001B[39;00m\n",
       "\u001B[1;32m    339\u001B[0m     \u001B[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001B[39;00m\n",
       "\u001B[1;32m    340\u001B[0m     \u001B[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001B[39;00m\n",
       "\u001B[1;32m    341\u001B[0m     \u001B[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001B[39;00m\n",
       "\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata_source\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:309\u001B[0m, in \u001B[0;36m_DataLoaderSource.dataloader\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance, pl\u001B[38;5;241m.\u001B[39mLightningDataModule):\n",
       "\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_datamodule_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:179\u001B[0m, in \u001B[0;36m_call_lightning_datamodule_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(fn):\n",
       "\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningDataModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mdatamodule\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n",
       "\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m<command-720585262726990>, line 45\u001B[0m, in \u001B[0;36mPinnerFormerDataset.train_dataloader\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_dataloader\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n",
       "\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersistent_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/fabric/utilities/data.py:324\u001B[0m, in \u001B[0;36m_wrap_init_method.<locals>.wrapper\u001B[0;34m(obj, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m store_explicit_arg \u001B[38;5;129;01min\u001B[39;00m kwargs:\n",
       "\u001B[1;32m    322\u001B[0m         \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstore_explicit_arg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, kwargs[store_explicit_arg])\n",
       "\u001B[0;32m--> 324\u001B[0m \u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__pl_inside_init\u001B[39m\u001B[38;5;124m\"\u001B[39m, old_inside_init)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:307\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n",
       "\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.\u001B[39;00m\n",
       "\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m shuffle \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m}:\n",
       "\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    309\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshuffle option, but got shuffle=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shuffle))\n",
       "\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sampler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# See NOTE [ Custom Samplers and IterableDataset ]\u001B[39;00m\n",
       "\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    314\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    315\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampler option, but got sampler=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sampler))\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-720585262727022>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    576\u001B[0m     ckpt_path,\n\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    579\u001B[0m )\n\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1031\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m-> 1033\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:197\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip:\n\u001B[1;32m    199\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:225\u001B[0m, in \u001B[0;36m_FitLoop.setup_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    222\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: resetting train dataloader\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    224\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_source\n\u001B[0;32m--> 225\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m \u001B[43m_request_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_dataloader()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(train_dataloader, CombinedLoader):\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:342\u001B[0m, in \u001B[0;36m_request_dataloader\u001B[0;34m(data_source)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \n\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    The requested dataloader\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _replace_dunder_methods(DataLoader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m), _replace_dunder_methods(BatchSampler):\n\u001B[1;32m    338\u001B[0m     \u001B[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001B[39;00m\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001B[39;00m\n\u001B[1;32m    340\u001B[0m     \u001B[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001B[39;00m\n\u001B[1;32m    341\u001B[0m     \u001B[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001B[39;00m\n\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata_source\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:309\u001B[0m, in \u001B[0;36m_DataLoaderSource.dataloader\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance, pl\u001B[38;5;241m.\u001B[39mLightningDataModule):\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_datamodule_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:179\u001B[0m, in \u001B[0;36m_call_lightning_datamodule_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(fn):\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningDataModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mdatamodule\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
        "File \u001B[0;32m<command-720585262726990>, line 45\u001B[0m, in \u001B[0;36mPinnerFormerDataset.train_dataloader\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_dataloader\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersistent_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/fabric/utilities/data.py:324\u001B[0m, in \u001B[0;36m_wrap_init_method.<locals>.wrapper\u001B[0;34m(obj, *args, **kwargs)\u001B[0m\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m store_explicit_arg \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[1;32m    322\u001B[0m         \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstore_explicit_arg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, kwargs[store_explicit_arg])\n\u001B[0;32m--> 324\u001B[0m \u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__pl_inside_init\u001B[39m\u001B[38;5;124m\"\u001B[39m, old_inside_init)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:307\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.\u001B[39;00m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m shuffle \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m}:\n\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    309\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshuffle option, but got shuffle=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shuffle))\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sampler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# See NOTE [ Custom Samplers and IterableDataset ]\u001B[39;00m\n\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    314\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    315\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampler option, but got sampler=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sampler))\n",
        "\u001B[0;31mValueError\u001B[0m: DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main_training_loop(num_tasks, num_proc_per_task):\n",
    " \n",
    "  from torch import optim, nn, utils, Tensor\n",
    "  from torchvision import datasets, transforms\n",
    "  from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "  import pytorch_lightning as pl\n",
    "  import mlflow\n",
    "  \n",
    "  print(\"running distributed training\")\n",
    "  ############################\n",
    "  ##### Setting up MLflow ####\n",
    "  # We need to do this so that different processes that will be able to find mlflow\n",
    "  os.environ['DATABRICKS_HOST'] = db_host\n",
    "  os.environ['DATABRICKS_TOKEN'] = db_token\n",
    "  \n",
    "  # NCCL P2P can cause issues with incorrect peer settings, so let's turn this off to scale for now\n",
    "  os.environ[\"NCCL_SOCKET_IFNAME\"] = \"eth0\"\n",
    "  os.environ['NCCL_P2P_DISABLE'] = '1'\n",
    "  os.environ['NCCL_DEBUG']='INFO'\n",
    "  \n",
    "  mlflow.set_experiment(experiment_path)\n",
    "  mlf_logger = pl.loggers.MLFlowLogger(experiment_name=experiment_path, run_id=run_id)\n",
    "  callback_lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "  \n",
    "  trainer = Trainer(\n",
    "    precision=16,\n",
    "    max_epochs=config[\"max_epochs\"],\n",
    "    limit_val_batches=config[\"limit_val_batches\"],\n",
    "    limit_train_batches=config[\"limit_train_batches\"],\n",
    "    val_check_interval = config[\"val_check_interval\"],\n",
    "    overfit_batches=config[\"overfit_batches\"],\n",
    "    log_every_n_steps = config[\"log_every_n_steps\"],\n",
    "    check_val_every_n_epoch=None,\n",
    "    accelerator=config[\"accelerator\"],\n",
    "    devices=num_proc_per_task, \n",
    "    strategy=\"ddp\",\n",
    "    logger=mlf_logger,\n",
    "    num_sanity_val_steps = config[\"num_sanity_val_steps\"],\n",
    "    callbacks=[callback_checkpoint, callback_lr_monitor]\n",
    "  )\n",
    "  trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64a2a7ea-169c-479c-ad06-87a5261578f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-720585262727022>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n",
       "\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n",
       "\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
       "\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n",
       "\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n",
       "\u001B[1;32m    576\u001B[0m     ckpt_path,\n",
       "\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m    579\u001B[0m )\n",
       "\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n",
       "\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n",
       "\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n",
       "\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[0;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n",
       "\u001B[1;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m   1031\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n",
       "\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n",
       "\u001B[0;32m-> 1033\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:197\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip:\n",
       "\u001B[1;32m    199\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:225\u001B[0m, in \u001B[0;36m_FitLoop.setup_data\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    222\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: resetting train dataloader\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    224\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_source\n",
       "\u001B[0;32m--> 225\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m \u001B[43m_request_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    226\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_dataloader()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(train_dataloader, CombinedLoader):\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:342\u001B[0m, in \u001B[0;36m_request_dataloader\u001B[0;34m(data_source)\u001B[0m\n",
       "\u001B[1;32m    331\u001B[0m \u001B[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001B[39;00m\n",
       "\u001B[1;32m    332\u001B[0m \n",
       "\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n",
       "\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    The requested dataloader\u001B[39;00m\n",
       "\u001B[1;32m    335\u001B[0m \n",
       "\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _replace_dunder_methods(DataLoader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m), _replace_dunder_methods(BatchSampler):\n",
       "\u001B[1;32m    338\u001B[0m     \u001B[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001B[39;00m\n",
       "\u001B[1;32m    339\u001B[0m     \u001B[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001B[39;00m\n",
       "\u001B[1;32m    340\u001B[0m     \u001B[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001B[39;00m\n",
       "\u001B[1;32m    341\u001B[0m     \u001B[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001B[39;00m\n",
       "\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata_source\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:309\u001B[0m, in \u001B[0;36m_DataLoaderSource.dataloader\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance, pl\u001B[38;5;241m.\u001B[39mLightningDataModule):\n",
       "\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_datamodule_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:179\u001B[0m, in \u001B[0;36m_call_lightning_datamodule_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(fn):\n",
       "\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningDataModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mdatamodule\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n",
       "\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m<command-720585262726990>, line 45\u001B[0m, in \u001B[0;36mPinnerFormerDataset.train_dataloader\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_dataloader\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n",
       "\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersistent_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/fabric/utilities/data.py:324\u001B[0m, in \u001B[0;36m_wrap_init_method.<locals>.wrapper\u001B[0;34m(obj, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m store_explicit_arg \u001B[38;5;129;01min\u001B[39;00m kwargs:\n",
       "\u001B[1;32m    322\u001B[0m         \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstore_explicit_arg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, kwargs[store_explicit_arg])\n",
       "\u001B[0;32m--> 324\u001B[0m \u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__pl_inside_init\u001B[39m\u001B[38;5;124m\"\u001B[39m, old_inside_init)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:307\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n",
       "\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.\u001B[39;00m\n",
       "\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m shuffle \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m}:\n",
       "\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    309\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshuffle option, but got shuffle=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shuffle))\n",
       "\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sampler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# See NOTE [ Custom Samplers and IterableDataset ]\u001B[39;00m\n",
       "\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    314\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    315\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampler option, but got sampler=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sampler))\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-720585262727022>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    576\u001B[0m     ckpt_path,\n\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    579\u001B[0m )\n\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1031\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m-> 1033\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:197\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip:\n\u001B[1;32m    199\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:225\u001B[0m, in \u001B[0;36m_FitLoop.setup_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    222\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: resetting train dataloader\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    224\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_source\n\u001B[0;32m--> 225\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m \u001B[43m_request_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_dataloader()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(train_dataloader, CombinedLoader):\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:342\u001B[0m, in \u001B[0;36m_request_dataloader\u001B[0;34m(data_source)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \n\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    The requested dataloader\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _replace_dunder_methods(DataLoader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m), _replace_dunder_methods(BatchSampler):\n\u001B[1;32m    338\u001B[0m     \u001B[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001B[39;00m\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001B[39;00m\n\u001B[1;32m    340\u001B[0m     \u001B[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001B[39;00m\n\u001B[1;32m    341\u001B[0m     \u001B[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001B[39;00m\n\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata_source\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:309\u001B[0m, in \u001B[0;36m_DataLoaderSource.dataloader\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance, pl\u001B[38;5;241m.\u001B[39mLightningDataModule):\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_datamodule_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:179\u001B[0m, in \u001B[0;36m_call_lightning_datamodule_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(fn):\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningDataModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mdatamodule\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
        "File \u001B[0;32m<command-720585262726990>, line 45\u001B[0m, in \u001B[0;36mPinnerFormerDataset.train_dataloader\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_dataloader\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersistent_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/fabric/utilities/data.py:324\u001B[0m, in \u001B[0;36m_wrap_init_method.<locals>.wrapper\u001B[0;34m(obj, *args, **kwargs)\u001B[0m\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m store_explicit_arg \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[1;32m    322\u001B[0m         \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstore_explicit_arg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, kwargs[store_explicit_arg])\n\u001B[0;32m--> 324\u001B[0m \u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__pl_inside_init\u001B[39m\u001B[38;5;124m\"\u001B[39m, old_inside_init)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:307\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.\u001B[39;00m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m shuffle \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m}:\n\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    309\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshuffle option, but got shuffle=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shuffle))\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sampler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# See NOTE [ Custom Samplers and IterableDataset ]\u001B[39;00m\n\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    314\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    315\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampler option, but got sampler=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sampler))\n",
        "\u001B[0;31mValueError\u001B[0m: DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_TASKS = 1\n",
    "NUM_PROC_PER_TASK = config[\"num_gpu\"]\n",
    "NUM_PROC = NUM_TASKS * NUM_PROC_PER_TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24fdbaf6-26b1-4a6c-a363-3c69f99f9b3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-720585262727022>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n",
       "\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n",
       "\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
       "\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n",
       "\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n",
       "\u001B[1;32m    576\u001B[0m     ckpt_path,\n",
       "\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m    579\u001B[0m )\n",
       "\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n",
       "\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n",
       "\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n",
       "\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[0;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n",
       "\u001B[1;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m   1031\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n",
       "\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n",
       "\u001B[0;32m-> 1033\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:197\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip:\n",
       "\u001B[1;32m    199\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:225\u001B[0m, in \u001B[0;36m_FitLoop.setup_data\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    222\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: resetting train dataloader\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    224\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_source\n",
       "\u001B[0;32m--> 225\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m \u001B[43m_request_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    226\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_dataloader()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(train_dataloader, CombinedLoader):\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:342\u001B[0m, in \u001B[0;36m_request_dataloader\u001B[0;34m(data_source)\u001B[0m\n",
       "\u001B[1;32m    331\u001B[0m \u001B[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001B[39;00m\n",
       "\u001B[1;32m    332\u001B[0m \n",
       "\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n",
       "\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    The requested dataloader\u001B[39;00m\n",
       "\u001B[1;32m    335\u001B[0m \n",
       "\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _replace_dunder_methods(DataLoader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m), _replace_dunder_methods(BatchSampler):\n",
       "\u001B[1;32m    338\u001B[0m     \u001B[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001B[39;00m\n",
       "\u001B[1;32m    339\u001B[0m     \u001B[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001B[39;00m\n",
       "\u001B[1;32m    340\u001B[0m     \u001B[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001B[39;00m\n",
       "\u001B[1;32m    341\u001B[0m     \u001B[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001B[39;00m\n",
       "\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata_source\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:309\u001B[0m, in \u001B[0;36m_DataLoaderSource.dataloader\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance, pl\u001B[38;5;241m.\u001B[39mLightningDataModule):\n",
       "\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_datamodule_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:179\u001B[0m, in \u001B[0;36m_call_lightning_datamodule_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(fn):\n",
       "\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningDataModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mdatamodule\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n",
       "\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m<command-720585262726990>, line 45\u001B[0m, in \u001B[0;36mPinnerFormerDataset.train_dataloader\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_dataloader\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n",
       "\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersistent_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/fabric/utilities/data.py:324\u001B[0m, in \u001B[0;36m_wrap_init_method.<locals>.wrapper\u001B[0;34m(obj, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m store_explicit_arg \u001B[38;5;129;01min\u001B[39;00m kwargs:\n",
       "\u001B[1;32m    322\u001B[0m         \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstore_explicit_arg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, kwargs[store_explicit_arg])\n",
       "\u001B[0;32m--> 324\u001B[0m \u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__pl_inside_init\u001B[39m\u001B[38;5;124m\"\u001B[39m, old_inside_init)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:307\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n",
       "\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.\u001B[39;00m\n",
       "\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m shuffle \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m}:\n",
       "\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    309\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshuffle option, but got shuffle=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shuffle))\n",
       "\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sampler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# See NOTE [ Custom Samplers and IterableDataset ]\u001B[39;00m\n",
       "\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    314\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    315\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampler option, but got sampler=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sampler))\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-720585262727022>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    576\u001B[0m     ckpt_path,\n\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    579\u001B[0m )\n\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1031\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m-> 1033\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:197\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip:\n\u001B[1;32m    199\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:225\u001B[0m, in \u001B[0;36m_FitLoop.setup_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    222\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: resetting train dataloader\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    224\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_source\n\u001B[0;32m--> 225\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m \u001B[43m_request_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_dataloader()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(train_dataloader, CombinedLoader):\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:342\u001B[0m, in \u001B[0;36m_request_dataloader\u001B[0;34m(data_source)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \n\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    The requested dataloader\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _replace_dunder_methods(DataLoader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m), _replace_dunder_methods(BatchSampler):\n\u001B[1;32m    338\u001B[0m     \u001B[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001B[39;00m\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001B[39;00m\n\u001B[1;32m    340\u001B[0m     \u001B[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001B[39;00m\n\u001B[1;32m    341\u001B[0m     \u001B[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001B[39;00m\n\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata_source\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:309\u001B[0m, in \u001B[0;36m_DataLoaderSource.dataloader\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance, pl\u001B[38;5;241m.\u001B[39mLightningDataModule):\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_datamodule_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:179\u001B[0m, in \u001B[0;36m_call_lightning_datamodule_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(fn):\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningDataModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mdatamodule\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
        "File \u001B[0;32m<command-720585262726990>, line 45\u001B[0m, in \u001B[0;36mPinnerFormerDataset.train_dataloader\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_dataloader\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersistent_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/fabric/utilities/data.py:324\u001B[0m, in \u001B[0;36m_wrap_init_method.<locals>.wrapper\u001B[0;34m(obj, *args, **kwargs)\u001B[0m\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m store_explicit_arg \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[1;32m    322\u001B[0m         \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstore_explicit_arg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, kwargs[store_explicit_arg])\n\u001B[0;32m--> 324\u001B[0m \u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__pl_inside_init\u001B[39m\u001B[38;5;124m\"\u001B[39m, old_inside_init)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:307\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.\u001B[39;00m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m shuffle \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m}:\n\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    309\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshuffle option, but got shuffle=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shuffle))\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sampler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# See NOTE [ Custom Samplers and IterableDataset ]\u001B[39;00m\n\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    314\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    315\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampler option, but got sampler=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sampler))\n",
        "\u001B[0;31mValueError\u001B[0m: DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.torch.distributor import TorchDistributor\n",
    "\n",
    "TorchDistributor(\n",
    "    num_processes=NUM_PROC, local_mode=False, use_gpu=True\n",
    ").run(main_training_loop, NUM_TASKS, NUM_PROC_PER_TASK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83e94e1f-e613-4355-b78a-409883d11a2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-720585262727022>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n",
       "\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n",
       "\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
       "\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n",
       "\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n",
       "\u001B[1;32m    576\u001B[0m     ckpt_path,\n",
       "\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m    579\u001B[0m )\n",
       "\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n",
       "\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n",
       "\u001B[1;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n",
       "\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n",
       "\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[0;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n",
       "\u001B[1;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
       "\u001B[1;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m   1031\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n",
       "\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n",
       "\u001B[0;32m-> 1033\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:197\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip:\n",
       "\u001B[1;32m    199\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:225\u001B[0m, in \u001B[0;36m_FitLoop.setup_data\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    222\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: resetting train dataloader\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    224\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_source\n",
       "\u001B[0;32m--> 225\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m \u001B[43m_request_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    226\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_dataloader()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(train_dataloader, CombinedLoader):\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:342\u001B[0m, in \u001B[0;36m_request_dataloader\u001B[0;34m(data_source)\u001B[0m\n",
       "\u001B[1;32m    331\u001B[0m \u001B[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001B[39;00m\n",
       "\u001B[1;32m    332\u001B[0m \n",
       "\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n",
       "\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    The requested dataloader\u001B[39;00m\n",
       "\u001B[1;32m    335\u001B[0m \n",
       "\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _replace_dunder_methods(DataLoader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m), _replace_dunder_methods(BatchSampler):\n",
       "\u001B[1;32m    338\u001B[0m     \u001B[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001B[39;00m\n",
       "\u001B[1;32m    339\u001B[0m     \u001B[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001B[39;00m\n",
       "\u001B[1;32m    340\u001B[0m     \u001B[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001B[39;00m\n",
       "\u001B[1;32m    341\u001B[0m     \u001B[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001B[39;00m\n",
       "\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata_source\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:309\u001B[0m, in \u001B[0;36m_DataLoaderSource.dataloader\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance, pl\u001B[38;5;241m.\u001B[39mLightningDataModule):\n",
       "\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_datamodule_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:179\u001B[0m, in \u001B[0;36m_call_lightning_datamodule_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(fn):\n",
       "\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningDataModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mdatamodule\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n",
       "\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m<command-720585262726990>, line 45\u001B[0m, in \u001B[0;36mPinnerFormerDataset.train_dataloader\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_dataloader\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n",
       "\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersistent_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/fabric/utilities/data.py:324\u001B[0m, in \u001B[0;36m_wrap_init_method.<locals>.wrapper\u001B[0;34m(obj, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m store_explicit_arg \u001B[38;5;129;01min\u001B[39;00m kwargs:\n",
       "\u001B[1;32m    322\u001B[0m         \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstore_explicit_arg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, kwargs[store_explicit_arg])\n",
       "\u001B[0;32m--> 324\u001B[0m \u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__pl_inside_init\u001B[39m\u001B[38;5;124m\"\u001B[39m, old_inside_init)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:307\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n",
       "\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.\u001B[39;00m\n",
       "\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m shuffle \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m}:\n",
       "\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    309\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshuffle option, but got shuffle=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shuffle))\n",
       "\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sampler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# See NOTE [ Custom Samplers and IterableDataset ]\u001B[39;00m\n",
       "\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    314\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    315\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampler option, but got sampler=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sampler))\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-720585262727022>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    576\u001B[0m     ckpt_path,\n\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    579\u001B[0m )\n\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1031\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m-> 1033\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:197\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip:\n\u001B[1;32m    199\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:225\u001B[0m, in \u001B[0;36m_FitLoop.setup_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    222\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: resetting train dataloader\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    224\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_source\n\u001B[0;32m--> 225\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m \u001B[43m_request_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_dataloader()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(train_dataloader, CombinedLoader):\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:342\u001B[0m, in \u001B[0;36m_request_dataloader\u001B[0;34m(data_source)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \n\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03mReturns:\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    The requested dataloader\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _replace_dunder_methods(DataLoader, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m), _replace_dunder_methods(BatchSampler):\n\u001B[1;32m    338\u001B[0m     \u001B[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001B[39;00m\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001B[39;00m\n\u001B[1;32m    340\u001B[0m     \u001B[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001B[39;00m\n\u001B[1;32m    341\u001B[0m     \u001B[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001B[39;00m\n\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata_source\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:309\u001B[0m, in \u001B[0;36m_DataLoaderSource.dataloader\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance, pl\u001B[38;5;241m.\u001B[39mLightningDataModule):\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_datamodule_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:179\u001B[0m, in \u001B[0;36m_call_lightning_datamodule_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(fn):\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningDataModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mdatamodule\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
        "File \u001B[0;32m<command-720585262726990>, line 45\u001B[0m, in \u001B[0;36mPinnerFormerDataset.train_dataloader\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_dataloader\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersistent_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/lightning/fabric/utilities/data.py:324\u001B[0m, in \u001B[0;36m_wrap_init_method.<locals>.wrapper\u001B[0;34m(obj, *args, **kwargs)\u001B[0m\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m store_explicit_arg \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[1;32m    322\u001B[0m         \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstore_explicit_arg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, kwargs[store_explicit_arg])\n\u001B[0;32m--> 324\u001B[0m \u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__pl_inside_init\u001B[39m\u001B[38;5;124m\"\u001B[39m, old_inside_init)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/utils/data/dataloader.py:307\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.\u001B[39;00m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m shuffle \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m}:\n\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    309\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshuffle option, but got shuffle=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shuffle))\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sampler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# See NOTE [ Custom Samplers and IterableDataset ]\u001B[39;00m\n\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    314\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    315\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampler option, but got sampler=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sampler))\n",
        "\u001B[0;31mValueError\u001B[0m: DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from pyspark.ml.torch.distributor import TorchDistributor\n",
    "\n",
    "# TorchDistributor(num_processes=NUM_PROC, local_mode=True, use_gpu=True).run(main_training_loop, NUM_TASKS, NUM_PROC_PER_TASK) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acd2b65d-e9c1-49d1-8c84-6e8ad03f5248",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Training-v2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}